[[【极客时间】李佳芮：ChatGPT 从0到1.pdf]]

## chatgpt能做什么

- 一问一答式的内容生成。
	- 虽然它可能一本正经地胡说八道，但大部分时候的回答很有参考价值。
- 完美理解我们的文字和问题
	- 只有我们想不到，没有它答不出来的。
- 持续对话，上下文理解和处理
	- 一直问，往广度，深度问都可以

## G P T分别指什么

### Generative 生成式
自发生成内容

### Pre-training 预训练
大规模的语料库上进行[[无监督学习]]。
就像人经过技能培训后，就可以解决问题一样。

- 监督学习
	- 有标签数据
	- 直接反馈
	- 预测结果
- 无监督学习
	- 无标签
	- 无反馈
	- 寻找数据中隐藏的结构
- 强化学习
	- 决策过程
	- 奖励机制
	- 学习一系列的行动


### Transformer 变换模型
基于自注意力机制的神经网络结构。
[[注意力机制]]


### 技术原理
通过预训练，它在生成回答的时候，就具备了预测下一个词的概率分布。所以我们使用的时候能看到，它的回答是一个字一个字蹦出来的。

## chatgpt的技术原理，本质是猜概率

两种文字模型区别：
- BERT
	- 双向语言模型
	- 猜中间的字，像完形填空
- GPT
	- 单向语言模型
	- 猜下一个字，像写作文

两种提示方式：
- fine-tuning
	- 调参。针对已经预训练好的模型，可以进行微调。
- prompt
	- 提示词。在问题中，加入特定的关键词、短语或句子，限定主题、语调
	- 对用户而言，我们使用的是zero shot prompt。比如跟gpt说，给我写一首诗，我们无需向他解释什么是诗，它已经知道。
	- gpt模型侧用的是few shot prompt。
	- 另一个角度考虑，embedding接口，其实是zero shot，因为我们给他一个文本，就返回描述的向量数据了。而competing接口，其实可以用few shot，比如先举几个例子，然后让它给我们回答一个新的问题的答案。。

一个关键概念
- [[RLHF]]

## chatgpt的前世今生

- 分析型ai
	- 比如抖音的推荐算法
- 生成式 ai，也就是 AIGC
	- AIGC的构词，模仿[[UGC、PGC和OGC的区别]]
	- 生成类型
		- 文本
		- 代码
		- 图片
		- 语音
		- 视频和3d模型
- 以前的chatbot
	- 划分专门的领域，比如sir，小爱同学
	- 意图和词槽slot
- 现在的chatgpt
	- 大语言模型+prompt，就能得到结果
	- 通用型，全能选手
![[Pasted image 20230329192147.png]]

## OpenAI

非常创新的股权架构：从非盈利性组织，转型成『利润上限』公司。
非常好地权衡了理想和现实。

## 自然语言编程 - prompt engineer

学会如何提问，清晰表达自己的想法。必要的时候，给example。




